{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Training a Network with tf.functions**"
      ],
      "metadata": {
        "id": "cHcPR-pyfkRL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qf-UkddKWZbF"
      },
      "outputs": [],
      "source": [
        "# importing required libraries and packages, which will be used through code.\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NCosPZTVWZbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0c65a38-7d8a-4fec-ad2e-a75e9a22571c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "68608000/68606236 [==============================] - 0s 0us/step\n",
            "68616192/68606236 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# this part downloads the cat vs dog dataset from the google servers, and extracts them. finally, you will have train and validation data paths in two variables.\n",
        "URL =     'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=URL, extract=True)\n",
        "\n",
        "PATH =          os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir                    =  \"/root/.keras/datasets/cats_and_dogs_filtered/train\"\n",
        "validation_dir           = \"/root/.keras/datasets/cats_and_dogs_filtered/validation\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first, we have defined the augmentation function with some tf.image attributes.\n",
        "def augment_data(image):\n",
        "    image = tf.image.resize_with_crop_or_pad(image, 150, 150)\n",
        "    image = tf.image.random_brightness(image, 0.5) \n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down   (image)\n",
        "    return image"
      ],
      "metadata": {
        "id": "xYVAJWOIpLLJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determining class names, will be used in the following function\n",
        "Class_Names=['cats','dogs']"
      ],
      "metadata": {
        "id": "fGMlWroYuORc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "t2rad4CHWZbO"
      },
      "outputs": [],
      "source": [
        "# Here, we have defined the get_label function, which assigns a one-hot coded label to each file-path\n",
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the     class-directory\n",
        "  return parts[-2] == Class_Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JYewkdJmWZbP",
        "outputId": "57b8c5ad-7a36-49ff-c8d6-18892ee11a8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True, False])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# a test on above-mentioned function\n",
        "get_label(\"/root/.keras/datasets/cats_and_dogs_filtered/train/cats/cat.0.jpg\").numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ncAdg8reWZbP"
      },
      "outputs": [],
      "source": [
        "# Next, we'll define a function to load an image, decode it, and change its tensor type to float 32.\n",
        "def load_img(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    \n",
        "    # https://stackoverflow.com/questions/44942729/tensorflowvalueerror-images-contains-no-shape\n",
        "    img = tf.image.decode_image(img, 3, expand_animations=False)\n",
        "    \n",
        "    img = tf.cast(img, tf.float32)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UgkSGTfJWZbP"
      },
      "outputs": [],
      "source": [
        "# A function to normalize the images between [-1, 1]\n",
        "def normalize(image):\n",
        "    image =  (image / 127.5)-1\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "T5mPexEFWZbQ"
      },
      "outputs": [],
      "source": [
        "# Here, the resizing function have been defined, which resizes to an arbitrary size given as input.\n",
        "def resize(image,height, width):\n",
        "    image = tf.image.resize(image, (height, width),\n",
        "                                 method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    #image = tf.image.resize_with_crop_or_pad(image, height, width)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7e23TVOOWZbQ"
      },
      "outputs": [],
      "source": [
        "# a function, which returns image and its label, using load_img and get_label functions,\n",
        "# corresponding to the given image_path.\n",
        "def load_image_with_label(image_path):\n",
        "    label = get_label(image_path)\n",
        "    img   =  load_img(image_path)\n",
        "    return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2Lk2D-IgWZbQ"
      },
      "outputs": [],
      "source": [
        "# a Function to load train data, which includes load_image_with_label, augment_data, and normalize functions\n",
        "def load_image_train(image_file):\n",
        "    image, label = load_image_with_label(image_file)\n",
        "    image = augment_data(image)\n",
        "    image =    normalize(image)\n",
        "    \n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dR3B0OlRWZbQ"
      },
      "outputs": [],
      "source": [
        "# a Function to load test data, which is similar to the previous one, but obviously doesn't include augment_data\n",
        "def load_image_test(image_file):\n",
        "    image, label = load_image_with_label(image_file)\n",
        "    image = resize(image, 150, 150)\n",
        "    image = normalize(image)\n",
        "\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-dYTmfE5WZbR"
      },
      "outputs": [],
      "source": [
        "# Determining batch-size and shuffle buffer size, which will be used further.\n",
        "BATCH_SIZE            = 32\n",
        "SHUFFLE_BUFFER_SIZE = 1000"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting train and validation directories from corresponding paths.\n",
        "train_dir      =             pathlib.Path(train_dir)\n",
        "validation_dir =        pathlib.Path(validation_dir)"
      ],
      "metadata": {
        "id": "Yn-hcw-02mUD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training and validation datasets are stored in two ShuffleDataset typed files.\n",
        "train_dataset     = tf.data.Dataset.list_files     (str(train_dir/'*/*'))\n",
        "validation_dataset= tf.data.Dataset.list_files(str(validation_dir/'*/*'))"
      ],
      "metadata": {
        "id": "iRxmXeiLyhrB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(list(train_dataset))     )\n",
        "print(len(list(validation_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG6fBYxRr9HH",
        "outputId": "eb085390-47cd-4a7d-dc7f-685cf6c8ead5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n",
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we will use AUTOTUNE in order to employ prefetch attribute for accelleration.\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "metadata": {
        "id": "yb10Bl1atgmg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "10y2ZLlpWZbR"
      },
      "outputs": [],
      "source": [
        "# Get train data set\n",
        "train_dataset = train_dataset.map(load_image_train)\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE)\n",
        "train_dataset = train_dataset.    batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.   prefetch(AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nbyv9w_MWZbR"
      },
      "outputs": [],
      "source": [
        "# Get validation data set\n",
        "validation_dataset = validation_dataset.map(load_image_test)\n",
        "validation_dataset = validation_dataset.batch(BATCH_SIZE)\n",
        "validation_dataset = validation_dataset.cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determinig and compiling a sequential network model \n",
        "from keras import layers\n",
        "from keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "base_model = tf.keras.applications.VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(150, 150, 3))\n",
        "base_model.trainable =                                False\n",
        "\n",
        "flatten_layer = layers.GlobalAveragePooling2D()\n",
        "dense_layer   = layers.Dense(100, activation='relu')\n",
        "dropout_layer = layers.Dropout(0.5)\n",
        "predict_layer = layers.Dense(2, activation='softmax')\n",
        "model = tf.keras.Sequential([\n",
        "  base_model   ,\n",
        "  flatten_layer,\n",
        "  dense_layer  ,\n",
        "  dropout_layer,\n",
        "  predict_layer\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "-0t5oqWM4pXp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "993905f0-4d51-4dea-d542-0c12973ba255"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "n1qcDnvc43dq",
        "outputId": "dae5d88b-3941-4f49-a9fb-6b18d6c99d68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               51300     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,766,190\n",
            "Trainable params: 51,502\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9DvauemfWZbT",
        "outputId": "06673d08-e336-4631-e3af-e597fa148bb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "63/63 [==============================] - 28s 177ms/step - loss: 0.7052 - acc: 0.5540 - val_loss: 0.6871 - val_acc: 0.5520\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 13s 146ms/step - loss: 0.6662 - acc: 0.6365 - val_loss: 0.6581 - val_acc: 0.6090\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 13s 149ms/step - loss: 0.6357 - acc: 0.6610 - val_loss: 0.6371 - val_acc: 0.6270\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 13s 149ms/step - loss: 0.6086 - acc: 0.6980 - val_loss: 0.6118 - val_acc: 0.6620\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 13s 152ms/step - loss: 0.5864 - acc: 0.7235 - val_loss: 0.5872 - val_acc: 0.7010\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.5644 - acc: 0.7525 - val_loss: 0.5756 - val_acc: 0.6860\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 13s 152ms/step - loss: 0.5474 - acc: 0.7550 - val_loss: 0.5577 - val_acc: 0.7000\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 13s 154ms/step - loss: 0.5304 - acc: 0.7675 - val_loss: 0.5456 - val_acc: 0.7020\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 14s 154ms/step - loss: 0.5106 - acc: 0.7785 - val_loss: 0.5146 - val_acc: 0.7500\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 13s 153ms/step - loss: 0.5015 - acc: 0.7835 - val_loss: 0.5096 - val_acc: 0.7490\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 14s 155ms/step - loss: 0.4832 - acc: 0.7930 - val_loss: 0.5132 - val_acc: 0.7260\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 13s 153ms/step - loss: 0.4717 - acc: 0.7955 - val_loss: 0.4918 - val_acc: 0.7510\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 13s 155ms/step - loss: 0.4629 - acc: 0.8015 - val_loss: 0.4884 - val_acc: 0.7460\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 13s 154ms/step - loss: 0.4487 - acc: 0.8010 - val_loss: 0.4833 - val_acc: 0.7470\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 13s 153ms/step - loss: 0.4422 - acc: 0.8095 - val_loss: 0.4786 - val_acc: 0.7530\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 13s 154ms/step - loss: 0.4309 - acc: 0.8260 - val_loss: 0.4618 - val_acc: 0.7600\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 13s 152ms/step - loss: 0.4294 - acc: 0.8025 - val_loss: 0.4500 - val_acc: 0.7670\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 13s 149ms/step - loss: 0.4155 - acc: 0.8185 - val_loss: 0.4422 - val_acc: 0.7720\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 13s 149ms/step - loss: 0.4220 - acc: 0.8155 - val_loss: 0.4337 - val_acc: 0.7770\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 13s 153ms/step - loss: 0.4038 - acc: 0.8190 - val_loss: 0.4417 - val_acc: 0.7730\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 13s 154ms/step - loss: 0.4098 - acc: 0.8225 - val_loss: 0.4580 - val_acc: 0.7650\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 14s 155ms/step - loss: 0.3944 - acc: 0.8245 - val_loss: 0.4245 - val_acc: 0.7840\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 14s 156ms/step - loss: 0.3989 - acc: 0.8230 - val_loss: 0.4171 - val_acc: 0.7910\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 14s 158ms/step - loss: 0.3896 - acc: 0.8195 - val_loss: 0.4236 - val_acc: 0.7900\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 14s 157ms/step - loss: 0.3879 - acc: 0.8310 - val_loss: 0.4233 - val_acc: 0.7910\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 13s 155ms/step - loss: 0.3906 - acc: 0.8280 - val_loss: 0.4020 - val_acc: 0.8000\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 13s 155ms/step - loss: 0.3951 - acc: 0.8240 - val_loss: 0.4040 - val_acc: 0.7980\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 13s 155ms/step - loss: 0.3680 - acc: 0.8460 - val_loss: 0.4013 - val_acc: 0.8020\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 14s 157ms/step - loss: 0.3651 - acc: 0.8385 - val_loss: 0.3902 - val_acc: 0.8050\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 13s 154ms/step - loss: 0.3653 - acc: 0.8465 - val_loss: 0.3924 - val_acc: 0.8050\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.3671 - acc: 0.8345 - val_loss: 0.3771 - val_acc: 0.8110\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.3592 - acc: 0.8445 - val_loss: 0.3733 - val_acc: 0.8150\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.3537 - acc: 0.8460 - val_loss: 0.3902 - val_acc: 0.8060\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.3531 - acc: 0.8500 - val_loss: 0.3709 - val_acc: 0.8150\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.3559 - acc: 0.8435 - val_loss: 0.3858 - val_acc: 0.8070\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 13s 148ms/step - loss: 0.3522 - acc: 0.8435 - val_loss: 0.3877 - val_acc: 0.8080\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.3426 - acc: 0.8480 - val_loss: 0.3826 - val_acc: 0.8090\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.3418 - acc: 0.8530 - val_loss: 0.3933 - val_acc: 0.8080\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 13s 149ms/step - loss: 0.3343 - acc: 0.8530 - val_loss: 0.3848 - val_acc: 0.8100\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.3336 - acc: 0.8580 - val_loss: 0.3681 - val_acc: 0.8160\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.3445 - acc: 0.8475 - val_loss: 0.3662 - val_acc: 0.8190\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.3394 - acc: 0.8475 - val_loss: 0.3561 - val_acc: 0.8240\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.3253 - acc: 0.8525 - val_loss: 0.3530 - val_acc: 0.8270\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 13s 149ms/step - loss: 0.3291 - acc: 0.8550 - val_loss: 0.3618 - val_acc: 0.8210\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 14s 156ms/step - loss: 0.3407 - acc: 0.8405 - val_loss: 0.3525 - val_acc: 0.8300\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.3361 - acc: 0.8550 - val_loss: 0.3514 - val_acc: 0.8310\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.3378 - acc: 0.8420 - val_loss: 0.3469 - val_acc: 0.8310\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.3282 - acc: 0.8530 - val_loss: 0.3440 - val_acc: 0.8320\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.3240 - acc: 0.8545 - val_loss: 0.3591 - val_acc: 0.8260\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.3194 - acc: 0.8615 - val_loss: 0.3669 - val_acc: 0.8210\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 13s 149ms/step - loss: 0.3260 - acc: 0.8605 - val_loss: 0.3394 - val_acc: 0.8340\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.3228 - acc: 0.8510 - val_loss: 0.3408 - val_acc: 0.8330\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.3089 - acc: 0.8655 - val_loss: 0.3796 - val_acc: 0.8170\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 13s 149ms/step - loss: 0.3233 - acc: 0.8555 - val_loss: 0.3412 - val_acc: 0.8330\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.3149 - acc: 0.8615 - val_loss: 0.3523 - val_acc: 0.8330\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.3150 - acc: 0.8610 - val_loss: 0.3556 - val_acc: 0.8310\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.3244 - acc: 0.8515 - val_loss: 0.3400 - val_acc: 0.8330\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 13s 146ms/step - loss: 0.3216 - acc: 0.8535 - val_loss: 0.3534 - val_acc: 0.8320\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.3083 - acc: 0.8640 - val_loss: 0.3506 - val_acc: 0.8350\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.3149 - acc: 0.8545 - val_loss: 0.3525 - val_acc: 0.8360\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.3176 - acc: 0.8555 - val_loss: 0.3451 - val_acc: 0.8340\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.2953 - acc: 0.8720 - val_loss: 0.3398 - val_acc: 0.8410\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 13s 149ms/step - loss: 0.3096 - acc: 0.8595 - val_loss: 0.3312 - val_acc: 0.8470\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.3027 - acc: 0.8650 - val_loss: 0.3244 - val_acc: 0.8510\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.2970 - acc: 0.8730 - val_loss: 0.3320 - val_acc: 0.8470\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.3106 - acc: 0.8595 - val_loss: 0.3303 - val_acc: 0.8490\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 13s 154ms/step - loss: 0.3081 - acc: 0.8680 - val_loss: 0.3344 - val_acc: 0.8460\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 13s 153ms/step - loss: 0.3024 - acc: 0.8695 - val_loss: 0.3159 - val_acc: 0.8580\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 13s 149ms/step - loss: 0.3064 - acc: 0.8630 - val_loss: 0.3418 - val_acc: 0.8430\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.2909 - acc: 0.8745 - val_loss: 0.3380 - val_acc: 0.8450\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 13s 153ms/step - loss: 0.3005 - acc: 0.8625 - val_loss: 0.3286 - val_acc: 0.8500\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.3012 - acc: 0.8725 - val_loss: 0.3394 - val_acc: 0.8460\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.2958 - acc: 0.8775 - val_loss: 0.3406 - val_acc: 0.8450\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 13s 153ms/step - loss: 0.2904 - acc: 0.8675 - val_loss: 0.3119 - val_acc: 0.8570\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 13s 153ms/step - loss: 0.3058 - acc: 0.8625 - val_loss: 0.3304 - val_acc: 0.8490\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.2937 - acc: 0.8670 - val_loss: 0.3238 - val_acc: 0.8550\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 13s 152ms/step - loss: 0.2953 - acc: 0.8650 - val_loss: 0.3337 - val_acc: 0.8500\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.2981 - acc: 0.8615 - val_loss: 0.3394 - val_acc: 0.8470\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 13s 152ms/step - loss: 0.2967 - acc: 0.8625 - val_loss: 0.3080 - val_acc: 0.8570\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.2927 - acc: 0.8720 - val_loss: 0.3310 - val_acc: 0.8500\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 13s 152ms/step - loss: 0.2948 - acc: 0.8690 - val_loss: 0.3202 - val_acc: 0.8560\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 13s 153ms/step - loss: 0.2914 - acc: 0.8725 - val_loss: 0.3249 - val_acc: 0.8530\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 14s 153ms/step - loss: 0.2855 - acc: 0.8770 - val_loss: 0.3253 - val_acc: 0.8520\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 13s 150ms/step - loss: 0.2916 - acc: 0.8745 - val_loss: 0.3310 - val_acc: 0.8500\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.3010 - acc: 0.8650 - val_loss: 0.3127 - val_acc: 0.8550\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.2913 - acc: 0.8710 - val_loss: 0.3314 - val_acc: 0.8520\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 13s 152ms/step - loss: 0.2904 - acc: 0.8620 - val_loss: 0.3183 - val_acc: 0.8550\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 13s 153ms/step - loss: 0.2923 - acc: 0.8745 - val_loss: 0.3243 - val_acc: 0.8510\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.2928 - acc: 0.8745 - val_loss: 0.3349 - val_acc: 0.8520\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 13s 152ms/step - loss: 0.2853 - acc: 0.8815 - val_loss: 0.3211 - val_acc: 0.8550\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 13s 152ms/step - loss: 0.2761 - acc: 0.8845 - val_loss: 0.3117 - val_acc: 0.8600\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 13s 153ms/step - loss: 0.2811 - acc: 0.8790 - val_loss: 0.3130 - val_acc: 0.8580\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.2934 - acc: 0.8655 - val_loss: 0.3140 - val_acc: 0.8590\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.2796 - acc: 0.8755 - val_loss: 0.3293 - val_acc: 0.8540\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.2855 - acc: 0.8780 - val_loss: 0.3257 - val_acc: 0.8510\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 13s 149ms/step - loss: 0.2870 - acc: 0.8805 - val_loss: 0.3063 - val_acc: 0.8630\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 13s 152ms/step - loss: 0.2717 - acc: 0.8865 - val_loss: 0.3437 - val_acc: 0.8480\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 13s 152ms/step - loss: 0.2839 - acc: 0.8700 - val_loss: 0.3134 - val_acc: 0.8610\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 13s 152ms/step - loss: 0.2734 - acc: 0.8835 - val_loss: 0.3247 - val_acc: 0.8510\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 13s 151ms/step - loss: 0.2876 - acc: 0.8750 - val_loss: 0.3009 - val_acc: 0.8630\n"
          ]
        }
      ],
      "source": [
        "# Finally, it's training time\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=100,\n",
        "                    validation_data=validation_dataset)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf2-GPU",
      "language": "python",
      "name": "tf2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "tf-functions-instead of-data-generator-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}